{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5: Statistics for Machine Learning\n",
    "\n",
    "Statistics is the backbone of machine learning. Today we'll master:\n",
    "\n",
    "1. **Descriptive Statistics**: Mean, median, mode, standard deviation\n",
    "2. **Probability Distributions**: Normal, binomial, uniform\n",
    "3. **Correlation vs Causation**: Understanding relationships\n",
    "4. **Hypothesis Testing**: Making data-driven decisions\n",
    "5. **Assignment**: Correlation analysis and hypothesis testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, binom, uniform, poisson, expon\n",
    "from scipy.stats import ttest_ind, ttest_1samp, chi2_contingency, pearsonr, spearmanr\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"SciPy Version: {stats.scipy.__version__ if hasattr(stats, 'scipy') else 'N/A'}\")\n",
    "print(\"Ready to learn Statistics for ML!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "titanic = sns.load_dataset('titanic')\n",
    "tips = sns.load_dataset('tips')\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "print(\"Datasets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Descriptive Statistics\n",
    "\n",
    "Descriptive statistics summarize and describe the main features of a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Measures of Central Tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "data = np.array([23, 25, 27, 28, 29, 30, 30, 31, 32, 35, 40, 150])  # Note: 150 is an outlier\n",
    "\n",
    "print(\"Sample Data:\", data)\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mean: Average of all values\n",
    "mean = np.mean(data)\n",
    "print(f\"\\nMean: {mean:.2f}\")\n",
    "print(f\"  Formula: sum(x) / n = {sum(data)} / {len(data)} = {mean:.2f}\")\n",
    "print(f\"  Note: Mean is sensitive to outliers (150 pulls it up)\")\n",
    "\n",
    "# Median: Middle value when sorted\n",
    "median = np.median(data)\n",
    "print(f\"\\nMedian: {median:.2f}\")\n",
    "print(f\"  The middle value (or average of two middle values)\")\n",
    "print(f\"  Note: Median is robust to outliers\")\n",
    "\n",
    "# Mode: Most frequent value\n",
    "mode_result = stats.mode(data, keepdims=True)\n",
    "print(f\"\\nMode: {mode_result.mode[0]} (appears {mode_result.count[0]} times)\")\n",
    "print(f\"  The most frequently occurring value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the difference\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# With outlier\n",
    "axes[0].hist(data, bins=10, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean:.1f}')\n",
    "axes[0].axvline(median, color='green', linestyle='--', linewidth=2, label=f'Median: {median:.1f}')\n",
    "axes[0].set_title('With Outlier (150)', fontsize=12)\n",
    "axes[0].legend()\n",
    "\n",
    "# Without outlier\n",
    "data_no_outlier = data[data < 100]\n",
    "mean_clean = np.mean(data_no_outlier)\n",
    "median_clean = np.median(data_no_outlier)\n",
    "\n",
    "axes[1].hist(data_no_outlier, bins=10, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].axvline(mean_clean, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_clean:.1f}')\n",
    "axes[1].axvline(median_clean, color='blue', linestyle='--', linewidth=2, label=f'Median: {median_clean:.1f}')\n",
    "axes[1].set_title('Without Outlier', fontsize=12)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean dropped from {mean:.1f} to {mean_clean:.1f} after removing outlier\")\n",
    "print(f\"Median only changed from {median:.1f} to {median_clean:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Measures of Dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(50, 15, 1000)  # mean=50, std=15\n",
    "\n",
    "print(\"Measures of Dispersion\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Range\n",
    "range_val = np.ptp(data)  # peak-to-peak\n",
    "print(f\"\\nRange: {range_val:.2f}\")\n",
    "print(f\"  Formula: max - min = {data.max():.2f} - {data.min():.2f}\")\n",
    "\n",
    "# Variance\n",
    "variance = np.var(data)\n",
    "print(f\"\\nVariance: {variance:.2f}\")\n",
    "print(f\"  Formula: Σ(x - mean)² / n\")\n",
    "print(f\"  Measures how spread out the data is (in squared units)\")\n",
    "\n",
    "# Standard Deviation\n",
    "std = np.std(data)\n",
    "print(f\"\\nStandard Deviation: {std:.2f}\")\n",
    "print(f\"  Formula: √variance = √{variance:.2f}\")\n",
    "print(f\"  Same unit as original data\")\n",
    "\n",
    "# Interquartile Range (IQR)\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "iqr = q3 - q1\n",
    "print(f\"\\nIQR: {iqr:.2f}\")\n",
    "print(f\"  Q1 (25th percentile): {q1:.2f}\")\n",
    "print(f\"  Q3 (75th percentile): {q3:.2f}\")\n",
    "print(f\"  IQR = Q3 - Q1 = {q3:.2f} - {q1:.2f}\")\n",
    "print(f\"  Robust to outliers, covers middle 50% of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of Variation\n",
    "cv = (std / np.mean(data)) * 100\n",
    "print(f\"\\nCoefficient of Variation (CV): {cv:.2f}%\")\n",
    "print(f\"  Formula: (std / mean) × 100\")\n",
    "print(f\"  Useful for comparing variability across different scales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize standard deviation\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create data with different standard deviations\n",
    "data1 = np.random.normal(50, 5, 1000)   # Low spread\n",
    "data2 = np.random.normal(50, 15, 1000)  # Medium spread\n",
    "data3 = np.random.normal(50, 30, 1000)  # High spread\n",
    "\n",
    "plt.hist(data1, bins=30, alpha=0.5, label=f'std=5 (tight)', color='blue')\n",
    "plt.hist(data2, bins=30, alpha=0.5, label=f'std=15 (medium)', color='green')\n",
    "plt.hist(data3, bins=30, alpha=0.5, label=f'std=30 (spread)', color='red')\n",
    "\n",
    "plt.axvline(50, color='black', linestyle='--', linewidth=2, label='Mean=50')\n",
    "plt.title('Effect of Standard Deviation on Data Spread', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Percentiles and Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles\n",
    "data = titanic['age'].dropna()\n",
    "\n",
    "print(\"Age Percentiles in Titanic Dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    value = np.percentile(data, p)\n",
    "    print(f\"{p}th percentile: {value:.1f} years\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - 50% of passengers were younger than {np.percentile(data, 50):.0f} years\")\n",
    "print(f\"  - 90% of passengers were younger than {np.percentile(data, 90):.0f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot showing quartiles\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "bp = axes[0].boxplot(data, vert=True, patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "\n",
    "# Add quartile labels\n",
    "axes[0].axhline(np.percentile(data, 25), color='green', linestyle='--', alpha=0.7)\n",
    "axes[0].axhline(np.percentile(data, 50), color='red', linestyle='--', alpha=0.7)\n",
    "axes[0].axhline(np.percentile(data, 75), color='green', linestyle='--', alpha=0.7)\n",
    "axes[0].set_title('Age Distribution (Box Plot)', fontsize=12)\n",
    "axes[0].set_ylabel('Age')\n",
    "\n",
    "# Annotate\n",
    "q1, q2, q3 = np.percentile(data, [25, 50, 75])\n",
    "axes[0].annotate(f'Q1: {q1:.0f}', xy=(1.1, q1), fontsize=10)\n",
    "axes[0].annotate(f'Q2 (Median): {q2:.0f}', xy=(1.1, q2), fontsize=10)\n",
    "axes[0].annotate(f'Q3: {q3:.0f}', xy=(1.1, q3), fontsize=10)\n",
    "\n",
    "# Histogram with quartile lines\n",
    "axes[1].hist(data, bins=30, edgecolor='black', alpha=0.7)\n",
    "for p, label, color in [(25, 'Q1', 'green'), (50, 'Median', 'red'), (75, 'Q3', 'green')]:\n",
    "    val = np.percentile(data, p)\n",
    "    axes[1].axvline(val, color=color, linestyle='--', linewidth=2, label=f'{label}: {val:.0f}')\n",
    "axes[1].set_title('Age Distribution with Quartiles', fontsize=12)\n",
    "axes[1].set_xlabel('Age')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness: Measure of asymmetry\n",
    "# Positive skew: tail extends to the right (mean > median)\n",
    "# Negative skew: tail extends to the left (mean < median)\n",
    "\n",
    "# Create different distributions\n",
    "np.random.seed(42)\n",
    "normal_data = np.random.normal(50, 10, 1000)\n",
    "right_skewed = np.random.exponential(10, 1000)  # Right-skewed\n",
    "left_skewed = 100 - np.random.exponential(10, 1000)  # Left-skewed\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, data, title in zip(axes, \n",
    "                            [left_skewed, normal_data, right_skewed],\n",
    "                            ['Left Skewed', 'Normal (Symmetric)', 'Right Skewed']):\n",
    "    ax.hist(data, bins=30, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(np.mean(data), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(data):.1f}')\n",
    "    ax.axvline(np.median(data), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(data):.1f}')\n",
    "    skew = stats.skew(data)\n",
    "    ax.set_title(f'{title}\\nSkewness: {skew:.2f}', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSkewness Interpretation:\")\n",
    "print(\"  Skewness < 0: Left-skewed (tail on left, mean < median)\")\n",
    "print(\"  Skewness = 0: Symmetric (normal distribution)\")\n",
    "print(\"  Skewness > 0: Right-skewed (tail on right, mean > median)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis: Measure of \"tailedness\"\n",
    "# High kurtosis: Heavy tails, more outliers\n",
    "# Low kurtosis: Light tails, fewer outliers\n",
    "\n",
    "np.random.seed(42)\n",
    "normal = np.random.normal(0, 1, 1000)\n",
    "heavy_tails = np.random.standard_t(df=3, size=1000)  # t-distribution with heavy tails\n",
    "light_tails = np.random.uniform(-2, 2, 1000)  # Uniform has light tails\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, data, title in zip(axes,\n",
    "                            [light_tails, normal, heavy_tails],\n",
    "                            ['Light Tails (Uniform)', 'Normal (Mesokurtic)', 'Heavy Tails (t-dist)']):\n",
    "    ax.hist(data, bins=30, edgecolor='black', alpha=0.7, density=True)\n",
    "    kurt = stats.kurtosis(data)\n",
    "    ax.set_title(f'{title}\\nExcess Kurtosis: {kurt:.2f}', fontsize=12)\n",
    "    ax.set_xlim(-6, 6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKurtosis Interpretation (Excess Kurtosis):\")\n",
    "print(\"  Kurtosis < 0: Platykurtic (light tails, flatter peak)\")\n",
    "print(\"  Kurtosis = 0: Mesokurtic (normal distribution)\")\n",
    "print(\"  Kurtosis > 0: Leptokurtic (heavy tails, sharper peak)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Probability Distributions\n",
    "\n",
    "Understanding probability distributions is essential for ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Normal (Gaussian) Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Distribution: Bell curve, most common in nature\n",
    "# Parameters: μ (mean), σ (standard deviation)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Different means\n",
    "x = np.linspace(-10, 20, 1000)\n",
    "for mu, color in [(0, 'blue'), (5, 'green'), (10, 'red')]:\n",
    "    axes[0].plot(x, norm.pdf(x, mu, 2), color=color, linewidth=2, label=f'μ={mu}, σ=2')\n",
    "axes[0].set_title('Effect of Mean (μ)', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('Probability Density')\n",
    "\n",
    "# Different standard deviations\n",
    "x = np.linspace(-15, 15, 1000)\n",
    "for sigma, color in [(1, 'blue'), (2, 'green'), (4, 'red')]:\n",
    "    axes[1].plot(x, norm.pdf(x, 0, sigma), color=color, linewidth=2, label=f'μ=0, σ={sigma}')\n",
    "axes[1].set_title('Effect of Standard Deviation (σ)', fontsize=12)\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('Probability Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 68-95-99.7 Rule (Empirical Rule)\n",
    "mu, sigma = 0, 1\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = norm.pdf(x, mu, sigma)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, y, 'b-', linewidth=2)\n",
    "\n",
    "# Fill areas\n",
    "# 1 std (68.27%)\n",
    "x1 = np.linspace(-1, 1, 100)\n",
    "plt.fill_between(x1, norm.pdf(x1, mu, sigma), alpha=0.3, color='blue', label='68.27% (±1σ)')\n",
    "\n",
    "# 2 std (95.45%)\n",
    "x2 = np.linspace(-2, 2, 100)\n",
    "plt.fill_between(x2, norm.pdf(x2, mu, sigma), alpha=0.2, color='green', label='95.45% (±2σ)')\n",
    "\n",
    "# 3 std (99.73%)\n",
    "x3 = np.linspace(-3, 3, 100)\n",
    "plt.fill_between(x3, norm.pdf(x3, mu, sigma), alpha=0.1, color='red', label='99.73% (±3σ)')\n",
    "\n",
    "# Add lines\n",
    "for i in range(-3, 4):\n",
    "    plt.axvline(i, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.title('The 68-95-99.7 Rule (Empirical Rule)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Standard Deviations from Mean')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"The Empirical Rule:\")\n",
    "print(\"  68.27% of data falls within 1 standard deviation of the mean\")\n",
    "print(\"  95.45% of data falls within 2 standard deviations of the mean\")\n",
    "print(\"  99.73% of data falls within 3 standard deviations of the mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-scores: How many standard deviations from the mean\n",
    "# z = (x - μ) / σ\n",
    "\n",
    "# Example: IQ scores (mean=100, std=15)\n",
    "mu_iq, sigma_iq = 100, 15\n",
    "\n",
    "print(\"IQ Score Analysis (μ=100, σ=15)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for iq in [70, 85, 100, 115, 130, 145]:\n",
    "    z = (iq - mu_iq) / sigma_iq\n",
    "    percentile = norm.cdf(z) * 100\n",
    "    print(f\"IQ {iq}: z-score = {z:+.2f}, percentile = {percentile:.1f}%\")\n",
    "\n",
    "print(f\"\\nWhat IQ is needed to be in top 1%?\")\n",
    "z_99 = norm.ppf(0.99)  # z-score for 99th percentile\n",
    "iq_99 = mu_iq + z_99 * sigma_iq\n",
    "print(f\"  z-score for 99th percentile: {z_99:.2f}\")\n",
    "print(f\"  IQ needed: {iq_99:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Binomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial: Number of successes in n independent trials\n",
    "# Parameters: n (number of trials), p (probability of success)\n",
    "\n",
    "# Example: Coin flips\n",
    "n = 10  # Number of flips\n",
    "p = 0.5  # Probability of heads\n",
    "\n",
    "x = np.arange(0, n+1)\n",
    "probabilities = binom.pmf(x, n, p)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(x, probabilities, color='steelblue', edgecolor='black')\n",
    "plt.title(f'Binomial Distribution: {n} Fair Coin Flips', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Heads')\n",
    "plt.ylabel('Probability')\n",
    "plt.xticks(x)\n",
    "\n",
    "# Add expected value\n",
    "expected = n * p\n",
    "plt.axvline(expected, color='red', linestyle='--', linewidth=2, label=f'Expected Value: {expected}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Expected value (μ) = n × p = {n} × {p} = {expected}\")\n",
    "print(f\"Variance = n × p × (1-p) = {n} × {p} × {1-p} = {n*p*(1-p)}\")\n",
    "print(f\"Standard deviation = √variance = {np.sqrt(n*p*(1-p)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different binomial distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "params = [(10, 0.5), (10, 0.2), (20, 0.5)]\n",
    "titles = ['n=10, p=0.5\\n(Fair coin)', 'n=10, p=0.2\\n(Biased)', 'n=20, p=0.5\\n(More trials)']\n",
    "\n",
    "for ax, (n, p), title in zip(axes, params, titles):\n",
    "    x = np.arange(0, n+1)\n",
    "    ax.bar(x, binom.pmf(x, n, p), color='steelblue', edgecolor='black')\n",
    "    ax.axvline(n*p, color='red', linestyle='--', linewidth=2, label=f'μ={n*p}')\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    ax.set_xlabel('Number of Successes')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: Quality Control\n",
    "# A factory produces items with 2% defect rate\n",
    "# What's the probability of finding exactly 3 defects in a batch of 100?\n",
    "\n",
    "n = 100  # Batch size\n",
    "p = 0.02  # Defect rate\n",
    "\n",
    "print(\"Quality Control Example\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Batch size: {n}, Defect rate: {p*100}%\")\n",
    "print()\n",
    "\n",
    "for k in range(0, 8):\n",
    "    prob = binom.pmf(k, n, p)\n",
    "    print(f\"P(exactly {k} defects) = {prob:.4f} ({prob*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nP(5 or more defects) = {1 - binom.cdf(4, n, p):.4f}\")\n",
    "print(f\"Expected defects = {n*p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform: All values equally likely\n",
    "# Parameters: a (minimum), b (maximum)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Continuous uniform\n",
    "a, b = 0, 10\n",
    "x = np.linspace(-2, 12, 1000)\n",
    "y = uniform.pdf(x, loc=a, scale=b-a)\n",
    "\n",
    "axes[0].plot(x, y, 'b-', linewidth=2)\n",
    "axes[0].fill_between(x, y, alpha=0.3)\n",
    "axes[0].set_title(f'Continuous Uniform [{a}, {b}]', fontsize=12)\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('Probability Density')\n",
    "axes[0].axvline((a+b)/2, color='red', linestyle='--', label=f'Mean: {(a+b)/2}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Discrete uniform (rolling a die)\n",
    "x = np.arange(1, 7)\n",
    "prob = np.ones(6) / 6\n",
    "\n",
    "axes[1].bar(x, prob, color='steelblue', edgecolor='black')\n",
    "axes[1].set_title('Discrete Uniform: Rolling a Die', fontsize=12)\n",
    "axes[1].set_xlabel('Outcome')\n",
    "axes[1].set_ylabel('Probability')\n",
    "axes[1].set_ylim(0, 0.25)\n",
    "axes[1].axhline(1/6, color='red', linestyle='--', label=f'P = 1/6 ≈ {1/6:.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Uniform Distribution Properties:\")\n",
    "print(f\"  Mean = (a + b) / 2 = ({a} + {b}) / 2 = {(a+b)/2}\")\n",
    "print(f\"  Variance = (b - a)² / 12 = {(b-a)**2/12:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Other Important Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Poisson distribution: Count of events in fixed time\n",
    "lambda_param = 5\n",
    "x_poisson = np.arange(0, 20)\n",
    "axes[0, 0].bar(x_poisson, poisson.pmf(x_poisson, lambda_param), color='purple', edgecolor='black')\n",
    "axes[0, 0].set_title(f'Poisson Distribution (λ={lambda_param})\\nEvents per time interval', fontsize=11)\n",
    "axes[0, 0].set_xlabel('Number of Events')\n",
    "axes[0, 0].set_ylabel('Probability')\n",
    "\n",
    "# Exponential distribution: Time between events\n",
    "x_exp = np.linspace(0, 5, 100)\n",
    "for rate in [0.5, 1, 2]:\n",
    "    axes[0, 1].plot(x_exp, expon.pdf(x_exp, scale=1/rate), linewidth=2, label=f'λ={rate}')\n",
    "axes[0, 1].set_title('Exponential Distribution\\nTime between events', fontsize=11)\n",
    "axes[0, 1].set_xlabel('Time')\n",
    "axes[0, 1].set_ylabel('Probability Density')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Chi-square distribution: Sum of squared standard normals\n",
    "x_chi = np.linspace(0, 20, 100)\n",
    "for df in [1, 2, 5, 10]:\n",
    "    axes[1, 0].plot(x_chi, stats.chi2.pdf(x_chi, df), linewidth=2, label=f'df={df}')\n",
    "axes[1, 0].set_title('Chi-Square Distribution\\nUsed in hypothesis testing', fontsize=11)\n",
    "axes[1, 0].set_xlabel('x')\n",
    "axes[1, 0].set_ylabel('Probability Density')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# t-distribution: Like normal but heavier tails\n",
    "x_t = np.linspace(-5, 5, 100)\n",
    "axes[1, 1].plot(x_t, norm.pdf(x_t), 'k--', linewidth=2, label='Normal')\n",
    "for df in [1, 5, 30]:\n",
    "    axes[1, 1].plot(x_t, stats.t.pdf(x_t, df), linewidth=2, label=f't (df={df})')\n",
    "axes[1, 1].set_title('t-Distribution\\nUsed with small samples', fontsize=11)\n",
    "axes[1, 1].set_xlabel('x')\n",
    "axes[1, 1].set_ylabel('Probability Density')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Correlation vs Causation\n",
    "\n",
    "One of the most important concepts in statistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation: Linear relationship (-1 to 1)\n",
    "# r = 1: Perfect positive correlation\n",
    "# r = 0: No linear correlation\n",
    "# r = -1: Perfect negative correlation\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create datasets with different correlations\n",
    "n = 100\n",
    "x = np.random.randn(n)\n",
    "\n",
    "y_strong_pos = x + np.random.randn(n) * 0.3  # r ≈ 0.95\n",
    "y_weak_pos = x + np.random.randn(n) * 2     # r ≈ 0.45\n",
    "y_no_corr = np.random.randn(n)               # r ≈ 0\n",
    "y_strong_neg = -x + np.random.randn(n) * 0.3  # r ≈ -0.95\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "datasets = [\n",
    "    (x, y_strong_pos, 'Strong Positive'),\n",
    "    (x, y_weak_pos, 'Weak Positive'),\n",
    "    (x, y_no_corr, 'No Correlation'),\n",
    "    (x, y_strong_neg, 'Strong Negative')\n",
    "]\n",
    "\n",
    "for ax, (xi, yi, title) in zip(axes.flatten(), datasets):\n",
    "    ax.scatter(xi, yi, alpha=0.6)\n",
    "    r, p = pearsonr(xi, yi)\n",
    "    ax.set_title(f'{title}\\nr = {r:.3f}, p-value = {p:.4f}', fontsize=11)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    \n",
    "    # Add regression line\n",
    "    m, b = np.polyfit(xi, yi, 1)\n",
    "    ax.plot(xi, m*xi + b, 'r-', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson vs Spearman correlation\n",
    "# Pearson: Measures linear relationship\n",
    "# Spearman: Measures monotonic relationship (based on ranks)\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.linspace(1, 10, 50)\n",
    "y_linear = 2*x + np.random.randn(50) * 2\n",
    "y_exponential = np.exp(x/3) + np.random.randn(50) * 5\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Linear relationship\n",
    "axes[0].scatter(x, y_linear)\n",
    "r_pearson, _ = pearsonr(x, y_linear)\n",
    "r_spearman, _ = spearmanr(x, y_linear)\n",
    "axes[0].set_title(f'Linear Relationship\\nPearson: {r_pearson:.3f}, Spearman: {r_spearman:.3f}', fontsize=11)\n",
    "\n",
    "# Exponential (non-linear) relationship\n",
    "axes[1].scatter(x, y_exponential)\n",
    "r_pearson, _ = pearsonr(x, y_exponential)\n",
    "r_spearman, _ = spearmanr(x, y_exponential)\n",
    "axes[1].set_title(f'Exponential Relationship\\nPearson: {r_pearson:.3f}, Spearman: {r_spearman:.3f}', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight:\")\n",
    "print(\"  Spearman correlation is better for non-linear monotonic relationships\")\n",
    "print(\"  Both coefficients are similar for linear relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Correlation Does NOT Imply Causation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Famous spurious correlations\n",
    "print(\"CORRELATION ≠ CAUSATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Examples of Spurious Correlations:\n",
    "\n",
    "1. Ice cream sales and drowning deaths\n",
    "   - Both increase in summer (confounding variable: temperature)\n",
    "   - Ice cream doesn't cause drowning!\n",
    "\n",
    "2. Number of firefighters and fire damage\n",
    "   - More firefighters at bigger fires = more damage\n",
    "   - Firefighters don't cause damage!\n",
    "\n",
    "3. Shoe size and reading ability in children\n",
    "   - Both increase with age (confounding variable: age)\n",
    "   - Bigger feet don't cause better reading!\n",
    "\n",
    "4. Nicolas Cage movies and pool drownings\n",
    "   - r = 0.67 (actual statistic!)\n",
    "   - Completely coincidental\n",
    "\"\"\")\n",
    "\n",
    "# Visualize confounding variable example\n",
    "np.random.seed(42)\n",
    "temperature = np.random.uniform(60, 100, 100)  # Temperature in F\n",
    "ice_cream = 10 * temperature + np.random.randn(100) * 50  # Ice cream sales\n",
    "drowning = 0.5 * temperature + np.random.randn(100) * 5  # Drowning incidents\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Ice cream vs Drowning\n",
    "axes[0].scatter(ice_cream, drowning, alpha=0.6, c='red')\n",
    "r, _ = pearsonr(ice_cream, drowning)\n",
    "axes[0].set_title(f'Ice Cream vs Drowning\\nr = {r:.3f}', fontsize=11)\n",
    "axes[0].set_xlabel('Ice Cream Sales')\n",
    "axes[0].set_ylabel('Drowning Incidents')\n",
    "\n",
    "# Temperature vs Ice cream\n",
    "axes[1].scatter(temperature, ice_cream, alpha=0.6, c='blue')\n",
    "axes[1].set_title('Temperature vs Ice Cream', fontsize=11)\n",
    "axes[1].set_xlabel('Temperature (F)')\n",
    "axes[1].set_ylabel('Ice Cream Sales')\n",
    "\n",
    "# Temperature vs Drowning\n",
    "axes[2].scatter(temperature, drowning, alpha=0.6, c='green')\n",
    "axes[2].set_title('Temperature vs Drowning', fontsize=11)\n",
    "axes[2].set_xlabel('Temperature (F)')\n",
    "axes[2].set_ylabel('Drowning Incidents')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTemperature is the CONFOUNDING VARIABLE!\")\n",
    "print(\"It causes both ice cream sales AND drowning incidents to increase.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Hypothesis Testing\n",
    "\n",
    "Making data-driven decisions with statistical rigor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Understanding Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HYPOTHESIS TESTING FRAMEWORK\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. FORMULATE HYPOTHESES:\n",
    "   - H₀ (Null Hypothesis): No effect, no difference (status quo)\n",
    "   - H₁ (Alternative Hypothesis): There IS an effect or difference\n",
    "\n",
    "2. CHOOSE SIGNIFICANCE LEVEL (α):\n",
    "   - Common values: 0.05 (5%), 0.01 (1%)\n",
    "   - Probability of rejecting H₀ when it's actually true (Type I error)\n",
    "\n",
    "3. CALCULATE TEST STATISTIC & P-VALUE:\n",
    "   - P-value: Probability of observing data this extreme if H₀ is true\n",
    "\n",
    "4. MAKE A DECISION:\n",
    "   - If p-value < α: Reject H₀ (result is statistically significant)\n",
    "   - If p-value ≥ α: Fail to reject H₀ (not enough evidence)\n",
    "\n",
    "IMPORTANT NOTES:\n",
    "   - Statistical significance ≠ Practical significance\n",
    "   - \"Fail to reject\" ≠ \"Accept\" (we can't prove the null)\n",
    "   - P-value is NOT the probability that H₀ is true\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 One-Sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample t-test: Compare sample mean to known value\n",
    "# Example: Is the average height different from 170 cm?\n",
    "\n",
    "np.random.seed(42)\n",
    "heights = np.random.normal(172, 8, 50)  # Sample of 50 heights\n",
    "\n",
    "hypothesized_mean = 170\n",
    "t_stat, p_value = ttest_1samp(heights, hypothesized_mean)\n",
    "\n",
    "print(\"One-Sample t-Test\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"H₀: μ = {hypothesized_mean} cm\")\n",
    "print(f\"H₁: μ ≠ {hypothesized_mean} cm\")\n",
    "print(f\"\\nSample size: {len(heights)}\")\n",
    "print(f\"Sample mean: {np.mean(heights):.2f} cm\")\n",
    "print(f\"Sample std: {np.std(heights, ddof=1):.2f} cm\")\n",
    "print(f\"\\nt-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\n✓ REJECT H₀ (p < {alpha}): Mean height is significantly different from {hypothesized_mean} cm\")\n",
    "else:\n",
    "    print(f\"\\n✗ FAIL TO REJECT H₀ (p ≥ {alpha}): No significant difference from {hypothesized_mean} cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Two-Sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-sample t-test: Compare means of two groups\n",
    "# Example: Did male and female passengers pay different fares?\n",
    "\n",
    "male_fares = titanic[titanic['sex'] == 'male']['fare'].dropna()\n",
    "female_fares = titanic[titanic['sex'] == 'female']['fare'].dropna()\n",
    "\n",
    "t_stat, p_value = ttest_ind(male_fares, female_fares)\n",
    "\n",
    "print(\"Two-Sample t-Test: Fare by Gender\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"H₀: μ_male = μ_female (no difference in fares)\")\n",
    "print(f\"H₁: μ_male ≠ μ_female (fares are different)\")\n",
    "print(f\"\\nMale passengers:\")\n",
    "print(f\"  n = {len(male_fares)}, mean = ${np.mean(male_fares):.2f}, std = ${np.std(male_fares):.2f}\")\n",
    "print(f\"\\nFemale passengers:\")\n",
    "print(f\"  n = {len(female_fares)}, mean = ${np.mean(female_fares):.2f}, std = ${np.std(female_fares):.2f}\")\n",
    "print(f\"\\nt-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.6f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\n✓ REJECT H₀: Significant difference in fares between genders\")\n",
    "else:\n",
    "    print(f\"\\n✗ FAIL TO REJECT H₀: No significant difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "sns.boxplot(data=titanic, x='sex', y='fare', ax=axes[0])\n",
    "axes[0].set_title('Fare Distribution by Gender', fontsize=12)\n",
    "\n",
    "# Histogram\n",
    "axes[1].hist(male_fares, bins=30, alpha=0.5, label='Male', color='blue')\n",
    "axes[1].hist(female_fares, bins=30, alpha=0.5, label='Female', color='red')\n",
    "axes[1].axvline(male_fares.mean(), color='blue', linestyle='--', linewidth=2)\n",
    "axes[1].axvline(female_fares.mean(), color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('Fare Distributions Overlaid', fontsize=12)\n",
    "axes[1].set_xlabel('Fare')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test: Test independence between categorical variables\n",
    "# Example: Is survival independent of gender?\n",
    "\n",
    "contingency_table = pd.crosstab(titanic['sex'], titanic['survived'])\n",
    "print(\"Contingency Table: Sex vs Survived\")\n",
    "print(contingency_table)\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"\\nChi-Square Test\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"H₀: Sex and survival are independent\")\n",
    "print(f\"H₁: Sex and survival are NOT independent\")\n",
    "print(f\"\\nChi-square statistic: {chi2:.2f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"p-value: {p_value:.2e}\")\n",
    "\n",
    "print(f\"\\nExpected frequencies (if independent):\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table.index, \n",
    "                   columns=contingency_table.columns).round(1))\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\n✓ REJECT H₀: Sex and survival are NOT independent (gender affects survival)\")\n",
    "else:\n",
    "    print(f\"\\n✗ FAIL TO REJECT H₀: Cannot conclude they are dependent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Observed counts\n",
    "contingency_table.plot(kind='bar', ax=axes[0], color=['#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Observed Counts', fontsize=12)\n",
    "axes[0].set_xlabel('Sex')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend(['Did not survive', 'Survived'])\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Survival rate\n",
    "survival_rate = titanic.groupby('sex')['survived'].mean() * 100\n",
    "bars = axes[1].bar(survival_rate.index, survival_rate.values, color=['#3498db', '#e74c3c'])\n",
    "for bar, rate in zip(bars, survival_rate.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                 f'{rate:.1f}%', ha='center', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Survival Rate by Gender', fontsize=12)\n",
    "axes[1].set_ylabel('Survival Rate (%)')\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Assignment: Correlation Analysis and Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT Part 1: Analyze correlations in the Tips dataset\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ASSIGNMENT PART 1: CORRELATION ANALYSIS (TIPS DATASET)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate correlations\n",
    "numeric_cols = tips.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = tips[numeric_cols].corr()\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            fmt='.3f', square=True, linewidths=0.5)\n",
    "plt.title('Tips Dataset - Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tip vs total_bill correlation with significance test\n",
    "r, p = pearsonr(tips['total_bill'], tips['tip'])\n",
    "\n",
    "print(\"\\nCorrelation: Tip vs Total Bill\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Pearson correlation coefficient: {r:.4f}\")\n",
    "print(f\"p-value: {p:.2e}\")\n",
    "\n",
    "if p < 0.05:\n",
    "    print(\"\\n✓ Correlation is statistically significant (p < 0.05)\")\n",
    "    \n",
    "# Interpret strength\n",
    "if abs(r) >= 0.7:\n",
    "    strength = \"strong\"\n",
    "elif abs(r) >= 0.4:\n",
    "    strength = \"moderate\"\n",
    "else:\n",
    "    strength = \"weak\"\n",
    "    \n",
    "direction = \"positive\" if r > 0 else \"negative\"\n",
    "print(f\"Interpretation: {strength} {direction} correlation\")\n",
    "print(f\"\\nAs total bill increases, tip tends to increase proportionally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=tips, x='total_bill', y='tip', \n",
    "            scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n",
    "plt.title(f'Tip vs Total Bill (r = {r:.3f})', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Total Bill ($)')\n",
    "plt.ylabel('Tip ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT Part 2: Hypothesis Testing\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ASSIGNMENT PART 2: HYPOTHESIS TESTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test 1: Do smokers tip differently than non-smokers?\n",
    "print(\"\\nTest 1: Do smokers tip differently than non-smokers?\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "smoker_tips = tips[tips['smoker'] == 'Yes']['tip']\n",
    "non_smoker_tips = tips[tips['smoker'] == 'No']['tip']\n",
    "\n",
    "t_stat, p_value = ttest_ind(smoker_tips, non_smoker_tips)\n",
    "\n",
    "print(f\"H₀: μ_smoker = μ_non_smoker\")\n",
    "print(f\"H₁: μ_smoker ≠ μ_non_smoker\")\n",
    "print(f\"\\nSmokers: n={len(smoker_tips)}, mean=${smoker_tips.mean():.2f}\")\n",
    "print(f\"Non-smokers: n={len(non_smoker_tips)}, mean=${non_smoker_tips.mean():.2f}\")\n",
    "print(f\"\\nt-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\n✓ REJECT H₀: Smokers tip significantly differently\")\n",
    "else:\n",
    "    print(\"\\n✗ FAIL TO REJECT H₀: No significant difference in tipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Is there a relationship between smoking and time of day?\n",
    "print(\"\\nTest 2: Is smoking related to time of day (lunch vs dinner)?\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "contingency = pd.crosstab(tips['smoker'], tips['time'])\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency)\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "print(f\"\\nH₀: Smoking and meal time are independent\")\n",
    "print(f\"H₁: Smoking and meal time are NOT independent\")\n",
    "print(f\"\\nChi-square: {chi2:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\n✓ REJECT H₀: Smoking is related to meal time\")\n",
    "else:\n",
    "    print(\"\\n✗ FAIL TO REJECT H₀: No significant relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Do tips differ by day of week?\n",
    "print(\"\\nTest 3: Do tips differ by day of week?\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# One-way ANOVA (F-test)\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "thur_tips = tips[tips['day'] == 'Thur']['tip']\n",
    "fri_tips = tips[tips['day'] == 'Fri']['tip']\n",
    "sat_tips = tips[tips['day'] == 'Sat']['tip']\n",
    "sun_tips = tips[tips['day'] == 'Sun']['tip']\n",
    "\n",
    "f_stat, p_value = f_oneway(thur_tips, fri_tips, sat_tips, sun_tips)\n",
    "\n",
    "print(f\"H₀: All days have equal mean tips\")\n",
    "print(f\"H₁: At least one day has different mean tip\")\n",
    "\n",
    "print(f\"\\nMean tips by day:\")\n",
    "for day in ['Thur', 'Fri', 'Sat', 'Sun']:\n",
    "    mean_tip = tips[tips['day'] == day]['tip'].mean()\n",
    "    print(f\"  {day}: ${mean_tip:.2f}\")\n",
    "\n",
    "print(f\"\\nF-statistic: {f_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\n✓ REJECT H₀: Tips differ significantly by day\")\n",
    "else:\n",
    "    print(\"\\n✗ FAIL TO REJECT H₀: No significant difference by day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all tests\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Test 1: Smoker vs Non-smoker tips\n",
    "sns.boxplot(data=tips, x='smoker', y='tip', ax=axes[0])\n",
    "axes[0].set_title('Tips by Smoker Status', fontsize=12)\n",
    "\n",
    "# Test 2: Smoking by time\n",
    "contingency.plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Smoking by Meal Time', fontsize=12)\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Test 3: Tips by day\n",
    "sns.boxplot(data=tips, x='day', y='tip', order=['Thur', 'Fri', 'Sat', 'Sun'], ax=axes[2])\n",
    "axes[2].set_title('Tips by Day of Week', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ASSIGNMENT SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "CORRELATION ANALYSIS:\n",
    "• Total bill and tip have a strong positive correlation (r ≈ 0.68)\n",
    "• This is statistically significant (p < 0.001)\n",
    "• As bill increases, tip increases proportionally\n",
    "\n",
    "HYPOTHESIS TESTING RESULTS:\n",
    "\n",
    "1. Smokers vs Non-smokers (t-test):\n",
    "   • No significant difference in tipping behavior\n",
    "   • Cannot conclude smoking affects tip amount\n",
    "\n",
    "2. Smoking and Meal Time (Chi-square):\n",
    "   • Significant relationship exists\n",
    "   • Smoking patterns differ between lunch and dinner\n",
    "\n",
    "3. Tips by Day (ANOVA):\n",
    "   • No significant difference between days\n",
    "   • Day of week doesn't affect tip amount\n",
    "\n",
    "KEY TAKEAWAYS:\n",
    "• Always check statistical significance before drawing conclusions\n",
    "• Correlation doesn't imply causation\n",
    "• Use appropriate tests for different data types\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Today you learned:\n",
    "\n",
    "### Descriptive Statistics\n",
    "- **Central Tendency**: Mean (average), Median (middle), Mode (most frequent)\n",
    "- **Dispersion**: Range, Variance, Standard Deviation, IQR\n",
    "- **Shape**: Skewness, Kurtosis\n",
    "\n",
    "### Probability Distributions\n",
    "- **Normal**: Bell curve, 68-95-99.7 rule, z-scores\n",
    "- **Binomial**: Successes in n trials\n",
    "- **Uniform**: All outcomes equally likely\n",
    "- **Others**: Poisson, Exponential, Chi-square, t-distribution\n",
    "\n",
    "### Correlation\n",
    "- **Pearson**: Linear relationships (-1 to 1)\n",
    "- **Spearman**: Monotonic relationships (based on ranks)\n",
    "- **Correlation ≠ Causation**: Confounding variables!\n",
    "\n",
    "### Hypothesis Testing\n",
    "- **Framework**: H₀, H₁, α, p-value, decision\n",
    "- **t-tests**: Compare means (one-sample, two-sample)\n",
    "- **Chi-square**: Test independence of categorical variables\n",
    "- **ANOVA**: Compare multiple group means\n",
    "\n",
    "---\n",
    "\n",
    "## Week 1 Complete!\n",
    "\n",
    "Congratulations! You've completed Week 1: Foundations & Data Mastery!\n",
    "\n",
    "You now have a solid foundation in:\n",
    "- ML concepts and environment setup\n",
    "- NumPy for numerical computing\n",
    "- Pandas for data manipulation\n",
    "- Visualization with Matplotlib and Seaborn\n",
    "- Statistics for machine learning\n",
    "\n",
    "**Next Week**: We'll start building actual ML models!\n",
    "\n",
    "---\n",
    "\n",
    "**Great job completing Day 5 and Week 1!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
