{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: Machine Learning Foundations & Environment Setup\n",
    "\n",
    "Welcome to Day 1 of your Machine Learning journey! Today we'll cover:\n",
    "\n",
    "1. **Understanding ML Types**: Supervised, Unsupervised, and Reinforcement Learning\n",
    "2. **Environment Verification**: Ensuring all packages are installed correctly\n",
    "3. **Dataset Exploration**: Loading and exploring Iris and Titanic datasets\n",
    "4. **Basic Visualizations**: Creating histograms and scatter plots\n",
    "5. **Assignment**: Writing about your ML problem of interest\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Machine Learning Types\n",
    "\n",
    "Machine Learning can be broadly categorized into three main types:\n",
    "\n",
    "### 1.1 Supervised Learning\n",
    "\n",
    "**Definition**: Learning from labeled data where we know the correct output for each input.\n",
    "\n",
    "**How it works**:\n",
    "- Input (X) → Model → Output (y)\n",
    "- The model learns the mapping between inputs and outputs\n",
    "- Uses historical data with known outcomes to make predictions\n",
    "\n",
    "**Types**:\n",
    "- **Classification**: Predicting categories (spam/not spam, cat/dog, disease/healthy)\n",
    "- **Regression**: Predicting continuous values (house prices, temperature, stock prices)\n",
    "\n",
    "**Real-world Examples**:\n",
    "- Email spam detection\n",
    "- Credit card fraud detection\n",
    "- House price prediction\n",
    "- Medical diagnosis\n",
    "- Image classification\n",
    "\n",
    "**Common Algorithms**:\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Support Vector Machines (SVM)\n",
    "- Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Unsupervised Learning\n",
    "\n",
    "**Definition**: Learning from unlabeled data where we don't know the correct output.\n",
    "\n",
    "**How it works**:\n",
    "- Input (X) → Model → Discover patterns/structure\n",
    "- The model finds hidden patterns or structures in data\n",
    "- No predefined labels or outcomes\n",
    "\n",
    "**Types**:\n",
    "- **Clustering**: Grouping similar items (customer segmentation, document clustering)\n",
    "- **Dimensionality Reduction**: Reducing features while preserving information (PCA, t-SNE)\n",
    "- **Association**: Finding rules that describe data (market basket analysis)\n",
    "- **Anomaly Detection**: Finding unusual patterns (fraud detection, network intrusion)\n",
    "\n",
    "**Real-world Examples**:\n",
    "- Customer segmentation for marketing\n",
    "- Recommendation systems (\"customers who bought X also bought Y\")\n",
    "- Image compression\n",
    "- Social network analysis\n",
    "- Gene expression analysis\n",
    "\n",
    "**Common Algorithms**:\n",
    "- K-Means Clustering\n",
    "- Hierarchical Clustering\n",
    "- DBSCAN\n",
    "- Principal Component Analysis (PCA)\n",
    "- Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reinforcement Learning\n",
    "\n",
    "**Definition**: Learning through interaction with an environment by receiving rewards or penalties.\n",
    "\n",
    "**How it works**:\n",
    "- Agent → Action → Environment → Reward/Penalty → Agent learns\n",
    "- The agent learns to make decisions by trial and error\n",
    "- Goal is to maximize cumulative reward over time\n",
    "\n",
    "**Key Concepts**:\n",
    "- **Agent**: The learner/decision maker\n",
    "- **Environment**: What the agent interacts with\n",
    "- **State**: Current situation of the agent\n",
    "- **Action**: What the agent can do\n",
    "- **Reward**: Feedback from the environment\n",
    "- **Policy**: Strategy that the agent employs\n",
    "\n",
    "**Real-world Examples**:\n",
    "- Game playing (AlphaGo, Chess, Video games)\n",
    "- Robotics (walking, manipulation)\n",
    "- Autonomous vehicles\n",
    "- Resource management\n",
    "- Trading algorithms\n",
    "\n",
    "**Common Algorithms**:\n",
    "- Q-Learning\n",
    "- Deep Q-Networks (DQN)\n",
    "- Policy Gradient Methods\n",
    "- Actor-Critic Methods\n",
    "- Proximal Policy Optimization (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Comparison Summary\n",
    "\n",
    "| Aspect | Supervised | Unsupervised | Reinforcement |\n",
    "|--------|------------|--------------|---------------|\n",
    "| **Data** | Labeled | Unlabeled | Interaction data |\n",
    "| **Goal** | Predict output | Find patterns | Maximize reward |\n",
    "| **Feedback** | Correct labels | None | Rewards/penalties |\n",
    "| **Example** | Spam detection | Customer clustering | Game playing |\n",
    "| **Difficulty** | Medium | Medium | High |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Environment Setup & Verification\n",
    "\n",
    "Let's verify that all necessary packages are installed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries and check versions\n",
    "import sys\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check versions\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "import matplotlib\n",
    "print(f\"Matplotlib Version: {matplotlib.__version__}\")\n",
    "print(f\"Seaborn Version: {sns.__version__}\")\n",
    "import sklearn\n",
    "print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All packages imported successfully!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib for inline display\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default figure size\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Visualization settings configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Loading and Exploring Datasets\n",
    "\n",
    "We'll work with two classic datasets:\n",
    "1. **Iris Dataset**: Classification of flower species (Supervised Learning)\n",
    "2. **Titanic Dataset**: Survival prediction (Supervised Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The Iris Dataset\n",
    "\n",
    "The Iris dataset is one of the most famous datasets in machine learning. It contains measurements of 150 iris flowers from 3 different species.\n",
    "\n",
    "**Features**:\n",
    "- Sepal length (cm)\n",
    "- Sepal width (cm)\n",
    "- Petal length (cm)\n",
    "- Petal width (cm)\n",
    "\n",
    "**Target**: Species (Setosa, Versicolor, Virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "iris_df = pd.DataFrame(\n",
    "    data=iris.data,\n",
    "    columns=iris.feature_names\n",
    ")\n",
    "\n",
    "# Add target variable\n",
    "iris_df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Iris Dataset - First 10 rows:\")\n",
    "print(\"=\"*80)\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Shape:\", iris_df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "for col in iris_df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(iris_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(\"=\"*80)\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "print(\"\\nSpecies Distribution:\")\n",
    "print(iris_df['species'].value_counts())\n",
    "print(\"\\nThe dataset is perfectly balanced with 50 samples per species!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(iris_df.isnull().sum())\n",
    "print(\"\\nNo missing values in the Iris dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics by species\n",
    "print(\"\\nMean values by species:\")\n",
    "print(\"=\"*80)\n",
    "iris_df.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Titanic Dataset\n",
    "\n",
    "The Titanic dataset contains information about passengers on the Titanic and whether they survived.\n",
    "\n",
    "**Features include**:\n",
    "- PassengerId, Name, Sex, Age\n",
    "- Ticket class (Pclass)\n",
    "- Number of siblings/spouses (SibSp)\n",
    "- Number of parents/children (Parch)\n",
    "- Ticket number, Fare, Cabin, Embarked port\n",
    "\n",
    "**Target**: Survived (0 = No, 1 = Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset from seaborn\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Titanic Dataset - First 10 rows:\")\n",
    "print(\"=\"*100)\n",
    "titanic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"Dataset Shape:\", titanic_df.shape)\n",
    "print(f\"\\nNumber of passengers: {len(titanic_df)}\")\n",
    "\n",
    "print(\"\\nColumn Names and Data Types:\")\n",
    "print(\"=\"*50)\n",
    "for col in titanic_df.columns:\n",
    "    print(f\"  {col}: {titanic_df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(\"Descriptive Statistics (Numerical Features):\")\n",
    "print(\"=\"*80)\n",
    "titanic_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features summary\n",
    "print(\"Categorical Features Summary:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "categorical_cols = titanic_df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(titanic_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(\"=\"*50)\n",
    "missing = titanic_df.isnull().sum()\n",
    "missing_percent = (missing / len(titanic_df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival statistics\n",
    "print(\"\\nSurvival Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total passengers: {len(titanic_df)}\")\n",
    "print(f\"Survived: {titanic_df['survived'].sum()} ({titanic_df['survived'].mean()*100:.1f}%)\")\n",
    "print(f\"Did not survive: {len(titanic_df) - titanic_df['survived'].sum()} ({(1-titanic_df['survived'].mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival by gender\n",
    "print(\"\\nSurvival Rate by Gender:\")\n",
    "print(titanic_df.groupby('sex')['survived'].agg(['count', 'sum', 'mean']))\n",
    "\n",
    "print(\"\\nSurvival Rate by Class:\")\n",
    "print(titanic_df.groupby('class')['survived'].agg(['count', 'sum', 'mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Basic Visualizations\n",
    "\n",
    "Visualizations help us understand data patterns quickly. Let's create some basic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Histograms\n",
    "\n",
    "Histograms show the distribution of a single numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for Iris dataset features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Distribution of Iris Features', fontsize=16, fontweight='bold')\n",
    "\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6']\n",
    "\n",
    "for idx, (col, ax) in enumerate(zip(iris.feature_names, axes.flatten())):\n",
    "    ax.hist(iris_df[col], bins=20, color=colors[idx], edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel(col, fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title(f'Distribution of {col}', fontsize=12)\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = iris_df[col].mean()\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms by species (overlaid)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Feature Distributions by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "species_colors = {'setosa': '#2ecc71', 'versicolor': '#3498db', 'virginica': '#e74c3c'}\n",
    "\n",
    "for col, ax in zip(iris.feature_names, axes.flatten()):\n",
    "    for species in iris.target_names:\n",
    "        data = iris_df[iris_df['species'] == species][col]\n",
    "        ax.hist(data, bins=15, alpha=0.5, label=species, color=species_colors[species])\n",
    "    \n",
    "    ax.set_xlabel(col, fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title(f'{col}', fontsize=12)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Age in Titanic dataset\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall age distribution\n",
    "axes[0].hist(titanic_df['age'].dropna(), bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Age', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Age Distribution of Titanic Passengers', fontsize=14)\n",
    "axes[0].axvline(titanic_df['age'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {titanic_df[\"age\"].mean():.1f}')\n",
    "axes[0].axvline(titanic_df['age'].median(), color='green', linestyle='--', linewidth=2,\n",
    "                label=f'Median: {titanic_df[\"age\"].median():.1f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Age by survival\n",
    "survived = titanic_df[titanic_df['survived'] == 1]['age'].dropna()\n",
    "not_survived = titanic_df[titanic_df['survived'] == 0]['age'].dropna()\n",
    "\n",
    "axes[1].hist(survived, bins=30, alpha=0.6, label='Survived', color='green', edgecolor='black')\n",
    "axes[1].hist(not_survived, bins=30, alpha=0.6, label='Did not survive', color='red', edgecolor='black')\n",
    "axes[1].set_xlabel('Age', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Age Distribution by Survival', fontsize=14)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Fare in Titanic dataset\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Regular scale\n",
    "axes[0].hist(titanic_df['fare'], bins=50, color='purple', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Fare', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Fare Distribution (Regular Scale)', fontsize=14)\n",
    "\n",
    "# Log scale for better visualization of skewed data\n",
    "fare_nonzero = titanic_df['fare'][titanic_df['fare'] > 0]\n",
    "axes[1].hist(np.log1p(fare_nonzero), bins=30, color='orange', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Log(Fare + 1)', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Fare Distribution (Log Scale)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Scatter Plots\n",
    "\n",
    "Scatter plots show the relationship between two numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Sepal Length vs Sepal Width\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for species in iris.target_names:\n",
    "    data = iris_df[iris_df['species'] == species]\n",
    "    plt.scatter(data['sepal length (cm)'], data['sepal width (cm)'], \n",
    "                label=species, alpha=0.7, s=100, edgecolor='black')\n",
    "\n",
    "plt.xlabel('Sepal Length (cm)', fontsize=12)\n",
    "plt.ylabel('Sepal Width (cm)', fontsize=12)\n",
    "plt.title('Iris: Sepal Length vs Sepal Width', fontsize=14, fontweight='bold')\n",
    "plt.legend(title='Species', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Petal Length vs Petal Width\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for species in iris.target_names:\n",
    "    data = iris_df[iris_df['species'] == species]\n",
    "    plt.scatter(data['petal length (cm)'], data['petal width (cm)'], \n",
    "                label=species, alpha=0.7, s=100, edgecolor='black')\n",
    "\n",
    "plt.xlabel('Petal Length (cm)', fontsize=12)\n",
    "plt.ylabel('Petal Width (cm)', fontsize=12)\n",
    "plt.title('Iris: Petal Length vs Petal Width', fontsize=14, fontweight='bold')\n",
    "plt.legend(title='Species', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how Setosa is clearly separated from the other two species!\")\n",
    "print(\"Petal measurements are excellent features for classification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All pairwise scatter plots for Iris\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Pairwise Feature Relationships in Iris Dataset', fontsize=16, fontweight='bold')\n",
    "\n",
    "feature_pairs = [\n",
    "    ('sepal length (cm)', 'sepal width (cm)'),\n",
    "    ('sepal length (cm)', 'petal length (cm)'),\n",
    "    ('sepal length (cm)', 'petal width (cm)'),\n",
    "    ('sepal width (cm)', 'petal length (cm)'),\n",
    "    ('sepal width (cm)', 'petal width (cm)'),\n",
    "    ('petal length (cm)', 'petal width (cm)')\n",
    "]\n",
    "\n",
    "for ax, (feat1, feat2) in zip(axes.flatten(), feature_pairs):\n",
    "    for species in iris.target_names:\n",
    "        data = iris_df[iris_df['species'] == species]\n",
    "        ax.scatter(data[feat1], data[feat2], label=species, alpha=0.6, s=50)\n",
    "    \n",
    "    ax.set_xlabel(feat1.replace(' (cm)', ''))\n",
    "    ax.set_ylabel(feat2.replace(' (cm)', ''))\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Age vs Fare in Titanic (colored by survival)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Filter out missing values\n",
    "titanic_clean = titanic_df.dropna(subset=['age', 'fare'])\n",
    "\n",
    "colors = ['red' if s == 0 else 'green' for s in titanic_clean['survived']]\n",
    "plt.scatter(titanic_clean['age'], titanic_clean['fare'], c=colors, alpha=0.5, s=50)\n",
    "\n",
    "# Create legend manually\n",
    "plt.scatter([], [], c='green', alpha=0.5, label='Survived')\n",
    "plt.scatter([], [], c='red', alpha=0.5, label='Did not survive')\n",
    "\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Fare', fontsize=12)\n",
    "plt.title('Titanic: Age vs Fare (colored by Survival)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with class information\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "markers = {1: 'o', 2: 's', 3: '^'}\n",
    "class_names = {1: 'First Class', 2: 'Second Class', 3: 'Third Class'}\n",
    "\n",
    "for pclass in [1, 2, 3]:\n",
    "    data = titanic_clean[titanic_clean['pclass'] == pclass]\n",
    "    survived = data[data['survived'] == 1]\n",
    "    not_survived = data[data['survived'] == 0]\n",
    "    \n",
    "    plt.scatter(survived['age'], survived['fare'], \n",
    "                marker=markers[pclass], c='green', alpha=0.5, s=60,\n",
    "                label=f'{class_names[pclass]} - Survived')\n",
    "    plt.scatter(not_survived['age'], not_survived['fare'], \n",
    "                marker=markers[pclass], c='red', alpha=0.5, s=60,\n",
    "                label=f'{class_names[pclass]} - Died')\n",
    "\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Fare', fontsize=12)\n",
    "plt.title('Titanic: Age vs Fare by Class and Survival', fontsize=14, fontweight='bold')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Additional Basic Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: Survival by class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count by class\n",
    "survival_by_class = titanic_df.groupby('class')['survived'].agg(['sum', 'count'])\n",
    "survival_by_class['died'] = survival_by_class['count'] - survival_by_class['sum']\n",
    "\n",
    "x = range(len(survival_by_class))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar([i - width/2 for i in x], survival_by_class['sum'], width, label='Survived', color='green', alpha=0.7)\n",
    "axes[0].bar([i + width/2 for i in x], survival_by_class['died'], width, label='Died', color='red', alpha=0.7)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(survival_by_class.index)\n",
    "axes[0].set_xlabel('Passenger Class', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Survival Count by Class', fontsize=14)\n",
    "axes[0].legend()\n",
    "\n",
    "# Survival rate by class\n",
    "survival_rate = titanic_df.groupby('class')['survived'].mean() * 100\n",
    "bars = axes[1].bar(survival_rate.index, survival_rate.values, color=['gold', 'silver', 'brown'], alpha=0.7)\n",
    "axes[1].set_xlabel('Passenger Class', fontsize=12)\n",
    "axes[1].set_ylabel('Survival Rate (%)', fontsize=12)\n",
    "axes[1].set_title('Survival Rate by Class', fontsize=14)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for bar, rate in zip(bars, survival_rate.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                 f'{rate:.1f}%', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for Iris features by species\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Feature Distribution by Species (Box Plots)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for col, ax in zip(iris.feature_names, axes.flatten()):\n",
    "    iris_df.boxplot(column=col, by='species', ax=ax)\n",
    "    ax.set_xlabel('Species')\n",
    "    ax.set_ylabel(col)\n",
    "    ax.set_title(col)\n",
    "\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Key Insights from Data Exploration\n",
    "\n",
    "### Iris Dataset Insights:\n",
    "\n",
    "1. **Perfect Balance**: All three species have exactly 50 samples each\n",
    "2. **Clear Separation**: Setosa is easily distinguishable from Versicolor and Virginica\n",
    "3. **Best Features**: Petal length and petal width provide the best separation between species\n",
    "4. **No Missing Data**: The dataset is clean with no missing values\n",
    "\n",
    "### Titanic Dataset Insights:\n",
    "\n",
    "1. **Survival Rate**: About 38% of passengers survived\n",
    "2. **Gender Impact**: Women had a much higher survival rate (~74%) than men (~19%)\n",
    "3. **Class Impact**: First-class passengers had the highest survival rate (~63%)\n",
    "4. **Missing Data**: Age (~20%) and deck information have significant missing values\n",
    "5. **Fare Distribution**: Highly skewed with some very expensive tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Assignment: \"What ML Problem Do I Want to Solve?\"\n",
    "\n",
    "Write a 200-word essay on a machine learning problem you want to solve. Consider:\n",
    "\n",
    "1. **Problem Description**: What problem do you want to address?\n",
    "2. **ML Type**: Is it supervised, unsupervised, or reinforcement learning?\n",
    "3. **Data Requirements**: What data would you need?\n",
    "4. **Impact**: Why is this problem worth solving?\n",
    "5. **Challenges**: What challenges might you face?\n",
    "\n",
    "### Example Response:\n",
    "\n",
    "---\n",
    "\n",
    "**My ML Problem: Predicting Customer Churn**\n",
    "\n",
    "I want to build a machine learning model to predict customer churn for a subscription-based service. This is a **supervised learning classification problem** where the target variable is whether a customer will cancel their subscription (churn=1) or remain active (churn=0).\n",
    "\n",
    "The data I would need includes:\n",
    "- Customer demographics (age, location, account age)\n",
    "- Usage patterns (frequency, features used, session duration)\n",
    "- Support interactions (tickets, complaints, satisfaction scores)\n",
    "- Payment history (on-time payments, payment method)\n",
    "- Historical churn labels\n",
    "\n",
    "This problem is worth solving because customer retention is significantly cheaper than acquisition. By identifying at-risk customers early, businesses can take proactive measures like personalized offers or improved support.\n",
    "\n",
    "Challenges include:\n",
    "- Class imbalance (churned customers are usually minority)\n",
    "- Feature engineering to capture behavioral patterns\n",
    "- Defining the prediction window (when to predict churn)\n",
    "- Making the model interpretable for business stakeholders\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Assignment Space - Write your 200-word essay here\n",
    "\n",
    "my_ml_problem = \"\"\"\n",
    "# My ML Problem: [Your Title Here]\n",
    "\n",
    "[Write your 200-word essay here...]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Count words in your essay\n",
    "word_count = len(my_ml_problem.split())\n",
    "print(f\"Current word count: {word_count} words\")\n",
    "if word_count < 200:\n",
    "    print(f\"You need {200 - word_count} more words to reach 200.\")\n",
    "else:\n",
    "    print(\"Great! You've met the word count requirement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Summary\n",
    "\n",
    "Today you learned:\n",
    "\n",
    "1. **Three Types of ML**:\n",
    "   - Supervised Learning: Learning from labeled data\n",
    "   - Unsupervised Learning: Finding patterns in unlabeled data\n",
    "   - Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "2. **Environment Setup**: Verified Python and essential libraries are installed\n",
    "\n",
    "3. **Data Exploration**:\n",
    "   - Loading datasets with scikit-learn and seaborn\n",
    "   - Basic statistics with pandas (.describe(), .value_counts())\n",
    "   - Checking for missing values (.isnull().sum())\n",
    "   - Grouping and aggregation (.groupby().mean())\n",
    "\n",
    "4. **Visualizations**:\n",
    "   - Histograms for distributions\n",
    "   - Scatter plots for relationships\n",
    "   - Bar charts for categorical comparisons\n",
    "   - Box plots for distributions by category\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Tomorrow (Day 2), we'll dive deep into **NumPy Fundamentals** - the foundation of numerical computing in Python!\n",
    "\n",
    "---\n",
    "\n",
    "**Great job completing Day 1!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
